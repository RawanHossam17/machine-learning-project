{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c8ae24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Used to display a progress bar\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set Paths and Target Size\n",
    "# **TODO: \n",
    "DATA_DIR = 'cell_images' \n",
    "TARGET_SIZE = (128, 128) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes: Parasitized (0) and Uninfected (1)\n",
    "CATEGORIES = ['Parasitized', 'Uninfected'] \n",
    "\n",
    "# Lists to store the processed image arrays (X) and their labels (y)\n",
    "all_processed_images = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, target_size=TARGET_SIZE):\n",
    "    \"\"\"Function to load, resize, and scale a single image.\"\"\"\n",
    "    \n",
    "    # 1. Load the image (OpenCV loads images in BGR format by default)\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Check for Integrity (Handle cases where the image fails to load)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    # 2. Standardize dimensions (Resizing)\n",
    "    # All images must have the same input size for the CNN\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "\n",
    "    # 3. Convert BGR to RGB (Most deep learning models expect RGB format)\n",
    "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 4. Scale the pixel values from [0, 255] to [0.0, 1.0]\n",
    "    # Scaling speeds up convergence during model training\n",
    "    img_scaled = img_rgb / 255.0\n",
    "\n",
    "    return img_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting Image Preprocessing for 2 Categories \n",
      "\n",
      "Processing 13779 images in category: Parasitized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Parasitized: 100%|██████████| 13779/13779 [03:18<00:00, 69.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 13779 images in category: Uninfected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Uninfected: 100%|██████████| 13779/13779 [03:04<00:00, 74.58it/s]\n"
     ]
    }
   ],
   "source": [
    "## Loop Through and Process all Images\n",
    "\n",
    "print(f\" Starting Image Preprocessing for {len(CATEGORIES)} Categories \")\n",
    "current_label = 0 # 0 for Parasitized, 1 for Uninfected\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATA_DIR, category)\n",
    "    # Get all image paths (assuming .png format)\n",
    "    image_paths = glob.glob(os.path.join(path, '*.png'))\n",
    "    \n",
    "    print(f\"\\nProcessing {len(image_paths)} images in category: {category}\")\n",
    "    \n",
    "    # Use tqdm to show a progress bar for the long loading process\n",
    "    for image_path in tqdm(image_paths, desc=f\"Cleaning {category}\"):\n",
    "        \n",
    "        processed_img = preprocess_image(image_path)\n",
    "        \n",
    "        if processed_img is not None:\n",
    "            # Append the processed image array\n",
    "            all_processed_images.append(processed_img)\n",
    "            # Append the corresponding label (0 or 1)\n",
    "            all_labels.append(current_label)\n",
    "        \n",
    "    current_label += 1 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finalizing Data Arrays\n",
      "SUCCESS: Total images processed: 27558\n",
      "Final Image Data Shape (X_images): (27558, 128, 128, 3)\n",
      "Final Label Data Shape (y_labels): (27558,)\n"
     ]
    }
   ],
   "source": [
    "## 2. Final Conversion to NumPy Arrays\n",
    "\n",
    "print(\"\\nFinalizing Data Arrays\")\n",
    "\n",
    "# Convert lists to NumPy arrays, which are mandatory for CNN input\n",
    "X_images = np.array(all_processed_images)\n",
    "y_labels = np.array(all_labels)\n",
    "\n",
    "print(f\"SUCCESS: Total images processed: {len(X_images)}\")\n",
    "# The final shape is (Number_of_Images, Height, Width, Color_Channels)\n",
    "print(f\"Final Image Data Shape (X_images): {X_images.shape}\")\n",
    "print(f\"Final Label Data Shape (y_labels): {y_labels.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Image Data Splitting Completed \n",
      "Total Images: 27558\n",
      "Training Images (80%): 22046\n",
      "Testing Images (20%): 5512\n",
      "Training Features Shape: (22046, 128, 128, 3)\n",
      "Testing Labels Shape: (5512,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_img = X_images      \n",
    "target_labels = y_labels     \n",
    "\n",
    "X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(\n",
    "    features_img, \n",
    "    target_labels, \n",
    "    test_size=0.20, \n",
    "    random_state=42,\n",
    "\n",
    "    stratify=target_labels\n",
    ")\n",
    "\n",
    "# Verify Dimensions\n",
    "print(\"\\n Image Data Splitting Completed \")\n",
    "print(f\"Total Images: {len(X_images)}\")\n",
    "print(f\"Training Images (80%): {len(X_train_img)}\")\n",
    "print(f\"Testing Images (20%): {len(X_test_img)}\")\n",
    "print(f\"Training Features Shape: {X_train_img.shape}\")\n",
    "print(f\"Testing Labels Shape: {y_test_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa304df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save the Training and Testing Images (Features)\n",
    "np.save('X_train_img.npy', X_train_img)\n",
    "np.save('X_test_img.npy', X_test_img)\n",
    "\n",
    "# 2. Save the Training and Testing Labels (Targets)\n",
    "np.save('y_train_img.npy', y_train_img)\n",
    "np.save('y_test_img.npy', y_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86c2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
